<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Japan Azure Big Data Support Blog</title>
  
  <subtitle>日本マイクロソフトの Azure Big data 処理に関する製品のサポート情報のブログです。</subtitle>
  <link href="https://jpaz-bigdata.github.io/blog/atom.xml" rel="self"/>
  
  <link href="https://jpaz-bigdata.github.io/blog/"/>
  <updated>2024-01-23T09:20:19.841Z</updated>
  <id>https://jpaz-bigdata.github.io/blog/</id>
  
  <author>
    <name>Azure Big Data Support Team</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Azure Data Factory を使用して SharePoint Online リストからデータをコピーする</title>
    <link href="https://jpaz-bigdata.github.io/blog/DataFactory/how-to-connect-sp-online/"/>
    <id>https://jpaz-bigdata.github.io/blog/DataFactory/how-to-connect-sp-online/</id>
    <published>2024-01-23T00:00:00.000Z</published>
    <updated>2024-01-23T09:20:19.841Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>注意：<br><a href="#c-azure-data-factory-%E3%81%8B%E3%82%89-sharepoint-online-%E3%82%B5%E3%82%A4%E3%83%88%E3%81%B8%E3%81%AE%E6%8E%A5%E7%B6%9A%E3%81%AE%E6%BA%96%E5%82%99">C. Azure Data Factory から SharePoint Online サイトへの接続の準備</a>で説明されているSharePoint Online アプリのアクセス許可の機能はすでに廃止となっており、2026 年 4 月 2 日には完全に使用できなくなります。詳しくは以下のドキュメントをご覧ください（英語のみ）。<br><a href="https://learn.microsoft.com/en-us/sharepoint/dev/sp-add-ins/retirement-announcement-for-azure-acs">Azure ACS retirement in Microsoft 365 | Microsoft Learn</a></p></blockquote><!-- omit in toc --><h2 id="目次"><a href="#目次" class="headerlink" title="目次"></a>目次</h2><ul><li><a href="#%E5%89%8D%E6%8F%90%E6%9D%A1%E4%BB%B6">前提条件</a></li><li><a href="#%E5%8F%82%E8%80%83%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88">参考ドキュメント</a></li><li><a href="#a-microsoft-id-%E3%83%97%E3%83%A9%E3%83%83%E3%83%88%E3%83%95%E3%82%A9%E3%83%BC%E3%83%A0%E3%81%AB%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%92%E7%99%BB%E9%8C%B2%E3%81%99%E3%82%8B">A. Microsoft ID プラットフォームにアプリケーションを登録する</a></li><li><a href="#b-%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E3%82%AF%E3%83%A9%E3%82%A4%E3%82%A2%E3%83%B3%E3%83%88%E3%82%B7%E3%83%BC%E3%82%AF%E3%83%AC%E3%83%83%E3%83%88%E3%81%AE%E8%BF%BD%E5%8A%A0">B. アプリケーションのクライアントシークレットの追加</a></li><li><a href="#c-azure-data-factory-%E3%81%8B%E3%82%89-sharepoint-online-%E3%82%B5%E3%82%A4%E3%83%88%E3%81%B8%E3%81%AE%E6%8E%A5%E7%B6%9A%E3%81%AE%E6%BA%96%E5%82%99">C. Azure Data Factory から SharePoint Online サイトへの接続の準備</a></li><li><a href="#d-azure-data-factory-%E3%81%A7-sharepoint-online-%E3%83%AA%E3%82%B9%E3%83%88%E3%81%B8%E3%81%AE%E3%83%AA%E3%83%B3%E3%82%AF-%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B">D. Azure Data Factory で SharePoint Online リストへのリンク サービスを作成する</a></li><li><a href="#e-azure-data-factory-%E3%81%A7-sharepoint-online-%E3%83%AA%E3%82%B9%E3%83%88%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B">E. Azure Data Factory で SharePoint Online リストのデータセットを作成する</a></li><li><a href="#f-azure-data-factory-%E3%81%A7-blob-%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B8%E3%81%B8%E3%81%AE%E3%83%AA%E3%83%B3%E3%82%AF%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B">F. Azure Data Factory で Blob ストレージへのリンクサービスを作成する</a></li><li><a href="#g-azure-data-factory-%E3%81%A7%E3%82%B7%E3%83%B3%E3%82%AF%E3%81%AE-blob-%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B8%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B">G. Azure Data Factory でシンクの Blob ストレージのデータセットを作成する</a></li><li><a href="#h-azure-data-factory-%E3%81%A7-sharepoint-online-%E3%83%AA%E3%82%B9%E3%83%88%E3%81%8B%E3%82%89-blob-%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B8%E3%81%B8%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC-%E3%82%A2%E3%82%AF%E3%83%86%E3%82%A3%E3%83%93%E3%83%86%E3%82%A3%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B">H. Azure Data Factory で SharePoint Online リストから Blob ストレージへのコピー アクティビティを作成する</a></li><li><a href="#i-%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3%E3%81%AE%E5%AE%9F%E8%A1%8C%E3%81%A8%E7%B5%90%E6%9E%9C%E3%81%AE%E7%A2%BA%E8%AA%8D">I. パイプラインの実行と結果の確認</a></li></ul><h2 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h2><ul><li>Azure Data Factory を作成済みであること。</li><li>ストレージ アカウントを作成済みであること。</li><li>SharePoint Online のリストを作成済みであること。</li></ul><h2 id="参考ドキュメント"><a href="#参考ドキュメント" class="headerlink" title="参考ドキュメント"></a>参考ドキュメント</h2><ul><li><a href="https://learn.microsoft.com/ja-jp/azure/data-factory/connector-sharepoint-online-list?tabs=data-factory">SharePoint Online リストからデータをコピーする - Azure Data Factory &amp; Azure Synapse | Microsoft Learn</a></li><li><a href="https://learn.microsoft.com/ja-jp/entra/identity-platform/quickstart-register-app">クイック スタート: Microsoft ID プラットフォームでアプリを登録する - Microsoft identity platform | Microsoft Learn</a></li></ul><h2 id="A-Microsoft-ID-プラットフォームにアプリケーションを登録する"><a href="#A-Microsoft-ID-プラットフォームにアプリケーションを登録する" class="headerlink" title="A. Microsoft ID プラットフォームにアプリケーションを登録する"></a>A. Microsoft ID プラットフォームにアプリケーションを登録する</h2><p><strong>1) クラウド アプリケーション管理者の権限を持つユーザで、<a href="https://entra.microsoft.com/#home">Microsoft - Microsoft Entra 管理センター</a>にアクセスします</strong><br>複数のテナントにアクセスできる場合は、上部のメニューの [設定] アイコンを使い、<br>[ディレクトリとサブスクリプション] メニューから SharePoint Online が存在するテナントに切り替えます。<br><img src="/blog/DataFactory/how-to-connect-sp-online/Entra-Setting-1.png"></p><p><strong>2) [ID] &gt; [アプリケーション] &gt; [アプリの登録] に移動し、 [新規登録] を選びます</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/Entra-Setting-2.png"></p><p><strong>3) アプリケーションの表示名を入力します</strong><br>表示名はサインイン時など、アプリケーションのユーザーがアプリを使用するときに表示されることがあります。  表示名はいつでも変更できます。<br><img src="/blog/DataFactory/how-to-connect-sp-online/Entra-Setting-3.png"></p><p><strong>4) [サポートされているアカウントの種類] では SharePoint Online に接続できるユーザー（アプリケーションを含む）を指定します</strong><br>各項目の説明は <a href="https://learn.microsoft.com/ja-jp/entra/identity-platform/quickstart-register-app#register-an-application">こちらのドキュメント</a>をご覧ください。<br>[リダイレクト URI (省略可能)] などその他の項目の入力は今回のケースでは不要です。<br><img src="/blog/DataFactory/how-to-connect-sp-online/Entra-Setting-4.png"></p><p><strong>5) [登録] をクリックして、アプリ登録を完了します</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/Entra-Setting-5.png"></p><p>登録が完了すると、Microsoft Entra 管理センターにアプリの登録の [概要] ペインが表示されます。<br>[アプリケーション (クライアント) ID] の値を確認します。 この値は、”クライアント ID” とも呼ばれ、<br>Microsoft ID プラットフォーム内のアプリケーションを一意に識別します。</p><p><strong>6) この画面で表示される [アプリケーション（クライアント） ID] 、 [ディレクトリ（テナント） ID] をメモしておきます</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/Entra-Setting-6.png"></p><h2 id="B-アプリケーションのクライアントシークレットの追加"><a href="#B-アプリケーションのクライアントシークレットの追加" class="headerlink" title="B. アプリケーションのクライアントシークレットの追加"></a>B. アプリケーションのクライアントシークレットの追加</h2><p><strong>1) 先ほどの画面から [証明書とシークレット] &gt; [クライアント シークレット] &gt; [新しいクライアント シークレット] を選択します</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/Client-Secret-1.png"></p><p><strong>2) クライアント シークレットの説明を追加します</strong><br>シークレットの有効期限を選択するか、カスタムの有効期間を指定します。<br>[追加] を選択します。<br><img src="/blog/DataFactory/how-to-connect-sp-online/Client-Secret-2.png"></p><p><strong>3) クライアント アプリケーションのコードで使用できるようにシークレットの値をコピーしておきます</strong><br>    <strong>このページから離れるとこのシークレットの値は 二度と表示されません。</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/Client-Secret-3.png"></p><h2 id="C-Azure-Data-Factory-から-SharePoint-Online-サイトへの接続の準備"><a href="#C-Azure-Data-Factory-から-SharePoint-Online-サイトへの接続の準備" class="headerlink" title="C. Azure Data Factory から SharePoint Online サイトへの接続の準備"></a>C. Azure Data Factory から SharePoint Online サイトへの接続の準備</h2><p><strong>1) 接続先の SharePoint Online でアクセス許可を設定します</strong><br>https://[your_site_url]/_layouts/15/appinv.aspx を開きます。<br>([your_site_url] の部分はお使いの SharePoint Online の URL に置き換えてください。)</p><p>先ほどの手順でメモしたアプリケーション ID を空欄に入力します。<br>[参照] をクリックすると設定した SharePoint Online の表示名が自動で入力されます。<br>その他の項目は以下のように入力します。</p><table><thead><tr><th align="left">設定項目</th><th align="left">入力内容</th></tr></thead><tbody><tr><td align="left">アプリドメイン</td><td align="left">localhost.com （今回のケースではダミーを使用します）</td></tr><tr><td align="left">リダイレクト URL</td><td align="left"><a href="https://www.localhost.com/">https://www.localhost.com</a>（今回のケースではダミーを使用します）</td></tr></tbody></table><p>権限の要求 XML には以下の内容をコピー &amp; ペーストで入力します。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">AppPermissionRequests</span> <span class="attr">AllowAppOnlyPolicy</span>=<span class="string">&quot;true&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">AppPermissionRequest</span> <span class="attr">Scope</span>=<span class="string">&quot;http://sharepoint/content/sitecollection/web&quot;</span> <span class="attr">Right</span>=<span class="string">&quot;Read&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">AppPermissionRequests</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>2) [作成] をクリックします</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/SharePoint-Access-1.png"></p><p><strong>3) [信頼する] をクリックします</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/SharePoint-Access-2.png"></p><h2 id="D-Azure-Data-Factory-で-SharePoint-Online-リストへのリンク-サービスを作成する"><a href="#D-Azure-Data-Factory-で-SharePoint-Online-リストへのリンク-サービスを作成する" class="headerlink" title="D. Azure Data Factory で SharePoint Online リストへのリンク サービスを作成する"></a>D. Azure Data Factory で SharePoint Online リストへのリンク サービスを作成する</h2><p><strong>1) Azure Data Factory の [管理] メニューに移動し、 [リンク サービス] を選択して、 [新規] をクリックします</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-1.png"></p><p><strong>2) SharePoint を検索し、[SharePoint Online リスト] コネクタを選択します</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-2.png"></p><p><strong>3) 入力フィールドに情報を入力して、テスト接続を行います</strong><br>サイト URL には接続対象の SharePoint Online の URL を入力します。<br>テナント ID、サービスプリンシパル ID、サービスプリンシパル キーには前の手順で登録した<br>テナント ID、アプリケーション ID、シークレット値をそれぞれ記入します。<br>入力が済んだら [テスト接続] をクリックして、 SharePoint Online との接続を確認します。<br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-3.png"></p><p>接続が成功したら [適用] をクリックしてリンク サービスを作成します。</p><h2 id="E-Azure-Data-Factory-で-SharePoint-Online-リストのデータセットを作成する"><a href="#E-Azure-Data-Factory-で-SharePoint-Online-リストのデータセットを作成する" class="headerlink" title="E. Azure Data Factory で SharePoint Online リストのデータセットを作成する"></a>E. Azure Data Factory で SharePoint Online リストのデータセットを作成する</h2><p><strong>1) [作成者] アイコン &gt; [データセット] &gt; […] メニュー &gt; [新しいデータセット] から接続先（SharePoint）のデータセットを作成します</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-4.png"></p><p><strong>2) [SharePoint Online リスト] を選択して、[続行] をクリックします</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-5.png"></p><p><strong>3) 入力フィールドに必要な情報を入力して [OK] を選択します</strong><br>任意の名前を入力し、先ほどの手順で作成したリンクサービスを選択します。<br>さらにコピー対象となる SharePoint Online のリスト名を選択して [OK] をクリックします。<br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-6.png"></p><h2 id="F-Azure-Data-Factory-で-Blob-ストレージへのリンクサービスを作成する"><a href="#F-Azure-Data-Factory-で-Blob-ストレージへのリンクサービスを作成する" class="headerlink" title="F. Azure Data Factory で Blob ストレージへのリンクサービスを作成する"></a>F. Azure Data Factory で Blob ストレージへのリンクサービスを作成する</h2><blockquote><p>今回の例では出力先を Azure BLOB ストレージの任意のディレクトリとします。<br>ストレージの作成方法等については、[ストレージ アカウントを作成する] (<a href="https://learn.microsoft.com/ja-jp/azure/storage/common/storage-account-create?tabs=azure-portal)%E3%82%92%E3%81%94%E8%A6%A7%E3%81%8F%E3%81%A0%E3%81%95%E3%81%84%E3%80%82">https://learn.microsoft.com/ja-jp/azure/storage/common/storage-account-create?tabs=azure-portal)をご覧ください。</a></p></blockquote><p><strong>1) Azure Data Factory の [管理] タブに移動し、[リンク サービス] を選択して、 [新規] をクリックします</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-7.png"></p><p><strong>2) Azure BLOB ストレージを選択し、[続行] をクリックします</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-8.png"></p><p><strong>3) 必要な情報を入力し、テスト接続ができることを確認します</strong><br>任意の名前を入力し、出力先となるストレージ アカウントを選択します。<br>テスト接続を行い、成功したら、[作成] をクリックします。<br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-9.png"></p><h2 id="G-Azure-Data-Factory-でシンクの-Blob-ストレージのデータセットを作成する"><a href="#G-Azure-Data-Factory-でシンクの-Blob-ストレージのデータセットを作成する" class="headerlink" title="G. Azure Data Factory でシンクの Blob ストレージのデータセットを作成する"></a>G. Azure Data Factory でシンクの Blob ストレージのデータセットを作成する</h2><p><strong>1) [作成者] アイコン &gt; データセット右の […] メニュー &gt; 新しいデータセットから接続先のデータセットを作成します</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-10.png"></p><p><strong>2) Azure Blob ストレージを選択して、 [続行] をクリックします</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-11.png"></p><p><strong>3) 出力形式は “DelimitedText” を選択して、 [続行] をクリックします</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-12.png"></p><p><strong>4) 必要な情報を入力し、データセットを作成します</strong><br>任意の名前を入力し、先の手順で作成したリンク サービスを選びます。<br>ファイルパスは任意の Blob ストレージのパスを入力します。<br>[先頭行をヘッダーとして] のチェックはそのままで [OK] をクリックします。<br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-13.png"></p><h2 id="H-Azure-Data-Factory-で-SharePoint-Online-リストから-Blob-ストレージへのコピー-アクティビティを作成する"><a href="#H-Azure-Data-Factory-で-SharePoint-Online-リストから-Blob-ストレージへのコピー-アクティビティを作成する" class="headerlink" title="H. Azure Data Factory で SharePoint Online リストから Blob ストレージへのコピー アクティビティを作成する"></a>H. Azure Data Factory で SharePoint Online リストから Blob ストレージへのコピー アクティビティを作成する</h2><p><strong>1) 新規にパイプラインを作成し、アクティビティの [移動と変換] から [データのコピー] アクティビティを選び、キャンバスにドラッグ &amp; ドロップで配置します</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-14.png"></p><p><strong>2) ソース タブで先ほど作成した、SharePoint Online のデータセットを選びます</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-15.png"></p><p><strong>3) 次にシンク タブで先ほど作成した Blob ストレージのデータセットを選びます</strong><br>また、必要に応じて他の項目も設定します。<br><img src="/blog/DataFactory/how-to-connect-sp-online/ADF-Setting-16.png"></p><h2 id="I-パイプラインの実行と結果の確認"><a href="#I-パイプラインの実行と結果の確認" class="headerlink" title="I. パイプラインの実行と結果の確認"></a>I. パイプラインの実行と結果の確認</h2><p><strong>1) 上記の設定が完了したら、[トリガーの追加] &gt; [今すぐトリガー] で実行します</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/Pipeline-Result-1.png"></p><p><strong>2) 画面一番左の [モニター] メニューの [パイプライン実行] で先ほどトリガー実行したパイプラインの結果を確認することが可能です</strong><br><img src="/blog/DataFactory/how-to-connect-sp-online/Pipeline-Result-2.png"></p><p>また、シンクの Blob ストレージで出力されたファイルを確認することも可能です。<br><img src="/blog/DataFactory/how-to-connect-sp-online/Pipeline-Result-3.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;注意：&lt;br&gt;&lt;a href=&quot;#c-azure-data-factory-%E3%81%8B%E3%82%89-sharepoint-online-%E3%82%B5%E3%82%A4%E3%83%88%E3%81%B8%E3%81%AE%E6%</summary>
      
    
    
    
    
    <category term="Azure" scheme="https://jpaz-bigdata.github.io/blog/tags/Azure/"/>
    
    <category term="Data Factory" scheme="https://jpaz-bigdata.github.io/blog/tags/Data-Factory/"/>
    
    <category term="SharePoint Online" scheme="https://jpaz-bigdata.github.io/blog/tags/SharePoint-Online/"/>
    
    <category term="SharePoint Online リスト" scheme="https://jpaz-bigdata.github.io/blog/tags/SharePoint-Online-%E3%83%AA%E3%82%B9%E3%83%88/"/>
    
  </entry>
  
  <entry>
    <title>シンクに出力するファイル名に日付やパイプライン実行 ID を加える方法</title>
    <link href="https://jpaz-bigdata.github.io/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/"/>
    <id>https://jpaz-bigdata.github.io/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/</id>
    <published>2023-06-22T00:00:00.000Z</published>
    <updated>2024-01-23T09:20:19.841Z</updated>
    
    <content type="html"><![CDATA[<p>シンクにデータを格納する際のファイル名に、実行時の日付やパイプライン実行 ID を加える方法をご紹介いたします。<br>ファイル名を操作するために、<a href="https://learn.microsoft.com/ja-jp/azure/data-factory/control-flow-expression-language-functions#date-functions">データ関数</a> や <a href="https://learn.microsoft.com/ja-jp/azure/data-factory/control-flow-system-variables">システム変数</a> と <a href="https://learn.microsoft.com/ja-jp/azure/data-factory/control-flow-expression-language-functions#concat">concat 関数</a> を用いた文字列結合を行うことで実現できます。  </p><p>また、<a href="https://learn.microsoft.com/ja-jp/azure/data-factory/control-flow-expression-language-functions#complex-expression-example">公式ドキュメントの複合式の例</a> も併せてご確認ください。</p><h1 id="検証環境"><a href="#検証環境" class="headerlink" title="検証環境"></a>検証環境</h1><ul><li>Azure Data Factory V2</li></ul><h1 id="手順"><a href="#手順" class="headerlink" title="手順"></a>手順</h1><h2 id="日付をファイル名に含める場合"><a href="#日付をファイル名に含める場合" class="headerlink" title="日付をファイル名に含める場合"></a>日付をファイル名に含める場合</h2><p>実行時における日付といった動的なコンテンツを追加するために、今回は [パイプライン式ビルダー] を用います。<br>[Datasets] の [ファイルパス] より、[動的なコンテンツの追加] を選択し、[パイプライン式ビルダー] を開きます。</p><p><img src="/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/date-setting-1.png">   </p><p>実行時のタイムスタンプを得るためには、データ関数の <code>utcnow()</code> を使うことで実現できます。また、パイプラインを呼び出したトリガーの実行時刻が必要な場合は、<code>@pipeline().TriggerTime</code> を使うことで実現が可能です。<br>今回は、下記の複合式を用いました。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@concat(&#x27;Test-&#x27;, formatDateTime(utcnow(), &#x27;yyyy-MM-dd&#x27;), &#x27;.csv&#x27;)</span><br></pre></td></tr></table></figure><p><img src="/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/date-setting-2.png">   </p><p>下記が実行結果となります。設定したシンクである Azure Blob Storage 上のファイル名に日付の情報が含まれていることが確認いただけます。</p><p><img src="/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/date-result-1.png"> </p><h2 id="パイプライン実行-ID-をファイル名に加える場合"><a href="#パイプライン実行-ID-をファイル名に加える場合" class="headerlink" title="パイプライン実行 ID をファイル名に加える場合"></a>パイプライン実行 ID をファイル名に加える場合</h2><p>同様に、[ファイルパス] より [パイプライン式ビルダー] を開きます。パイプラインの実行 ID を取得するには、システム変数の一つである <code>pipeline().RunId</code> を使うことで実現できます。<br>その他にも、ワークスペースの名前やパイプラインの名前を取得することも可能でございます。詳細は、<a href="https://learn.microsoft.com/ja-jp/azure/data-factory/control-flow-system-variables">システム変数</a> をご覧ください。  </p><p>今回は、下記の複合式を用いました。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@concat(&#x27;Test-&#x27;, pipeline().RunId, &#x27;.csv&#x27;)</span><br></pre></td></tr></table></figure><p><img src="/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/runid-setting-1.png">   </p><p>下記が実行結果となります。確かに、パイプラインの実行 ID がシンクである Azure Blob Storage 上のファイル名に含まれていることが確認できます。</p><p><img src="/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/runid-result-1.png"><br><img src="/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/runid-result-2.png">   </p><h2 id="パイプラインの変数からファイル名を渡す場合"><a href="#パイプラインの変数からファイル名を渡す場合" class="headerlink" title="パイプラインの変数からファイル名を渡す場合"></a>パイプラインの変数からファイル名を渡す場合</h2><p>これまでは、Datasets のファイルパスに書き込む形で実現していましたが、アクティビティの設定から指定する方法で実行します。<br>流れとしては、Datasets のパラメータを作成した後、ファイルパスに作成したパラメータを指定します。Datasets のパラメータに対して、アクティビティの設定から、所望の複合式を渡します。その際に、変数として設定しておく方法をご紹介いたします。</p><p>まず、[Datasets] の [パラメータ] から任意のパラメータを作成します。[規定値] は、空のままとします。</p><p><img src="/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/variable-setting-1.png"></p><p>[ファイルパス] の  [パイプライン式ビルダー] では、作成したパラメータを指定します。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@dataset().filename</span><br></pre></td></tr></table></figure><p>パイプライン キャンパスの背景を選び、[変数] タブを選択して、変数を追加します。</p><p><img src="/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/variable-setting-2.png"></p><p>アクティビティを選択し、[シンク] タブより、[シンク データセット] の [データセットのプロパティ] の [値] に、先ほど設定した変数を記入します。変数を呼びだすためには、下記のように <code>variables()</code> を用います。<br>以上の操作で、シンクに出力されるファイル名に日付を加えることが可能です。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@variables(&#x27;filename&#x27;)</span><br></pre></td></tr></table></figure><p><img src="/blog/DataFactory/how-to-add-variables-to-sink-filename-in-copy-activity/variable-setting-3.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;シンクにデータを格納する際のファイル名に、実行時の日付やパイプライン実行 ID を加える方法をご紹介いたします。&lt;br&gt;ファイル名を操作するために、&lt;a href=&quot;https://learn.microsoft.com/ja-jp/azure/data-factory/c</summary>
      
    
    
    
    
    <category term="Azure" scheme="https://jpaz-bigdata.github.io/blog/tags/Azure/"/>
    
    <category term="Data Factory" scheme="https://jpaz-bigdata.github.io/blog/tags/Data-Factory/"/>
    
    <category term="システム変数" scheme="https://jpaz-bigdata.github.io/blog/tags/%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E5%A4%89%E6%95%B0/"/>
    
    <category term="データ関数" scheme="https://jpaz-bigdata.github.io/blog/tags/%E3%83%87%E3%83%BC%E3%82%BF%E9%96%A2%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>サービスプリンシパル認証によるAzure Data Factory と Dynamics 365 (Microsoft Dataverse) の接続方法</title>
    <link href="https://jpaz-bigdata.github.io/blog/DataFactory/how-to-create-dataverse-linkedservice-by-service-principal/"/>
    <id>https://jpaz-bigdata.github.io/blog/DataFactory/how-to-create-dataverse-linkedservice-by-service-principal/</id>
    <published>2023-06-19T00:00:00.000Z</published>
    <updated>2024-01-23T09:20:19.849Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#%E7%9B%AE%E6%AC%A1">目次</a></li><li><a href="#%E6%A6%82%E8%A6%81">概要</a></li><li><a href="#%E6%A4%9C%E8%A8%BC%E7%92%B0%E5%A2%83">検証環境</a></li><li><a href="#%E6%89%8B%E9%A0%86">手順</a><ul><li><a href="#dataverse-%E5%81%B4%E3%81%AE%E6%8E%A5%E7%B6%9A%E6%A8%A9%E9%99%90%E4%BB%98%E4%B8%8E">Dataverse 側の接続権限付与</a></li><li><a href="#data-factory-%E5%81%B4%E3%81%AE%E6%8E%A5%E7%B6%9A%E6%83%85%E5%A0%B1%E5%8F%96%E5%BE%97-%E3%83%AA%E3%83%B3%E3%82%AF%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%AE%E4%BD%9C%E6%88%90">Data Factory 側の接続情報取得 (リンクサービスの作成)</a></li></ul></li></ul><h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>サービスプリンシパル認証を使った Data Factory と Dataverse  のリンクサービスの作成方法についてご紹介いたします。作成するにあたり、Dataverse に紐づくアプリケーションに関する情報の取得と Dataverse 側でのアクセス権限の付与が必要になります。<br><a href="https://learn.microsoft.com/ja-jp/azure/data-factory/connector-dynamics-crm-office-365?tabs=data-factory">Dataverse コネクタの公式ドキュメント</a> も併せてご確認ください。  </p><h1 id="検証環境"><a href="#検証環境" class="headerlink" title="検証環境"></a>検証環境</h1><ul><li>Azure Data Factory V2</li></ul><h1 id="手順"><a href="#手順" class="headerlink" title="手順"></a>手順</h1><h2 id="Dataverse-側の接続権限付与"><a href="#Dataverse-側の接続権限付与" class="headerlink" title="Dataverse 側の接続権限付与"></a>Dataverse 側の接続権限付与</h2><p>Azure AD 登録済みアプリケーションから Dataverse にアクセスするには Office 365 側の アプリ ユーザーが必要です。<br><a href="https://learn.microsoft.com/ja-jp/power-platform/admin/manage-application-users#create-an-application-user">Power Platform 管理センターでアプリケーション ユーザーを管理する</a> も併せてご確認ください。 </p><p>以下の手順で新しいアプリ ユーザーを作成します。   </p><p><a href="https://admin.powerplatform.microsoft.com/home">Power Platform 管理センター</a> にシステム管理者でアクセスします。<br>[環境] から該当する環境を選択します。  </p><p><img src="/blog/DataFactory/how-to-create-dataverse-linkedservice-by-service-principal/power-platform-1.png"></p><p>環境 URL を取得しておきます。Azure Data Factory のリンクサービスを作る際の、サービス URL の一部になります。<br>[設定] を選択します。  </p><p><img src="/blog/DataFactory/how-to-create-dataverse-linkedservice-by-service-principal/power-platform-2.png"></p><p> [ユーザーとアクセス許可] を選択してから、[アプリケーション ユーザー] を選択します。  </p><p><img src="/blog/DataFactory/how-to-create-dataverse-linkedservice-by-service-principal/power-platform-3.png"></p><p> [+ 新規アプリ ユーザー] を選択し、新しいアプリ ユーザーの作成ページを開きます。<br> [部署] で、ドロップダウン リストから部署を選択した後、 [セキュリティ ロール] の [編集] を選択します。<br> 新しいアプリケーション ユーザーに追加する、選択した部署におけるセキュリティ ロールを選択できます。[システム管理者] などのセキュリティ ロールを追加した後、[保存] を選択します。</p><p><img src="/blog/DataFactory/how-to-create-dataverse-linkedservice-by-service-principal/power-platform-4.png"></p><h2 id="Data-Factory-側の接続情報取得-リンクサービスの作成"><a href="#Data-Factory-側の接続情報取得-リンクサービスの作成" class="headerlink" title="Data Factory 側の接続情報取得 (リンクサービスの作成)"></a>Data Factory 側の接続情報取得 (リンクサービスの作成)</h2><p>Azure AD 登録されているアプリケーションの情報を取得する必要があります。<br>Azure Portal より [アプリの登録] から確認できます。  </p><p>[!TIP]<br>Azure AD にアプリケーションが登録されていない、もしくは、新たに登録が必要な場合は、<a href="https://learn.microsoft.com/ja-jp/azure/active-directory/develop/howto-create-service-principal-portal#register-an-application-with-azure-ad-and-create-a-service-principal">リソースにアクセスできる Azure Active Directory アプリケーションとサービス プリンシパルを作成する</a> を参考にご登録ください。  </p><p><img src="/blog/DataFactory/how-to-create-dataverse-linkedservice-by-service-principal/linked-service-1.png"></p><p>サービスプリンシパル認証に必要な ID とキーを取得します。<br>サービスプリンシパル ID は、[アプリ情報] -&gt; [概要] -&gt; [アプリケーションID] で取得できます。  </p><p><img src="/blog/DataFactory/how-to-create-dataverse-linkedservice-by-service-principal/linked-service-service-principal-id.png"></p><p>サービスプリンシパル キー は、[アプリ情報] -&gt; [証明書とシークレット] -&gt; [クライアントシークレット] で取得もしくは作成できます。  </p><p>[!IMPORTANT]<br>作成直後を除き、クライアント シークレットの値を後から確認できません。ページを終了する前に、必ず保存してください。  </p><p><img src="/blog/DataFactory/how-to-create-dataverse-linkedservice-by-service-principal/linked-service-service-principal-key.png"></p><p>得られた情報から、Azure Data Factory 上でリンクサービスの作成を行います。サービスURI は、Power Platform 管理センター で得られた環境URL を用います。必要に応じて、https://  などを加えてください。  </p><p><img src="/blog/DataFactory/how-to-create-dataverse-linkedservice-by-service-principal/linked-service-service.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E7%9B%AE%E6%AC%A1&quot;&gt;目次&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E6%A6%82%E8%A6%81&quot;&gt;概要&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E6%A4%9C%E8%A8%BC%E7%92%B0%E</summary>
      
    
    
    
    
    <category term="Azure" scheme="https://jpaz-bigdata.github.io/blog/tags/Azure/"/>
    
    <category term="Data Factory" scheme="https://jpaz-bigdata.github.io/blog/tags/Data-Factory/"/>
    
    <category term="Dataverse" scheme="https://jpaz-bigdata.github.io/blog/tags/Dataverse/"/>
    
    <category term="リンクサービス" scheme="https://jpaz-bigdata.github.io/blog/tags/%E3%83%AA%E3%83%B3%E3%82%AF%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9/"/>
    
  </entry>
  
  <entry>
    <title>Data Flowの外部呼び出し変換方法の参考例</title>
    <link href="https://jpaz-bigdata.github.io/blog/DataFactory/how-to-data-flow-external-call/"/>
    <id>https://jpaz-bigdata.github.io/blog/DataFactory/how-to-data-flow-external-call/</id>
    <published>2023-06-05T00:00:00.000Z</published>
    <updated>2024-01-23T09:20:19.853Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#%E7%9B%AE%E6%AC%A1">目次</a></li><li><a href="#%E6%A6%82%E8%A6%81">概要</a></li><li><a href="#%E6%A4%9C%E8%A8%BC%E7%92%B0%E5%A2%83">検証環境</a></li><li><a href="#%E6%89%8B%E9%A0%86">手順</a><ul><li><a href="#rest-api-%E3%81%AE%E6%BA%96%E5%82%99">REST API の準備</a></li><li><a href="#data-flow-%E3%81%AE%E6%BA%96%E5%82%99">Data Flow の準備</a></li><li><a href="#%E5%A4%96%E9%83%A8%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%97%E3%81%AE%E8%A8%AD%E5%AE%9A">外部呼び出しの設定</a><ul><li><a href="#rest-%E3%81%AE%E3%83%AA%E3%83%B3%E3%82%AF%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%AE%E4%BD%9C%E6%88%90">REST のリンクサービスの作成</a></li><li><a href="#%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%97%E5%A4%89%E6%8F%9B%E3%81%AE%E8%A8%AD%E5%AE%9A">呼び出し変換の設定</a></li><li><a href="#mapping-%E3%81%AE%E8%A8%AD%E5%AE%9A">Mapping の設定</a></li><li><a href="#output-%E3%81%AE%E8%A8%AD%E5%AE%9A">Output の設定</a></li></ul></li><li><a href="#%E5%A4%96%E9%83%A8%E5%91%BC%E3%81%B6%E5%87%BA%E3%81%97%E3%81%AE%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C%E3%81%AE%E7%A2%BA%E8%AA%8D">外部呼ぶ出しの実行結果の確認</a></li></ul></li><li><a href="#%E3%81%94%E7%B4%B9%E4%BB%8B%E3%81%97%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84%E6%A9%9F%E8%83%BD%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6">ご紹介していない機能について</a><ul><li><a href="#%E8%A1%8C%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E9%81%A9%E7%94%A8%E3%81%99%E3%82%8Bapi-%E3%82%92%E5%A4%89%E3%81%88%E3%81%9F%E3%81%84%E3%81%A8%E3%81%8D">行によって適用するAPI を変えたいとき</a></li><li><a href="#response-%E3%82%92%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AB%E5%8A%A0%E3%81%88%E3%81%9F%E3%81%84%E3%81%A8%E3%81%8D">Response をデータに加えたいとき</a></li></ul></li></ul><h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>Data Flowにおける外部呼び出し変換を使用すると、外部のREST API を行単位で適用することが可能です。<br>この記事では、投稿日時点での機能を用いて、外部呼び出しの使用例をご紹介します。<br><a href="https://learn.microsoft.com/ja-jp/azure/data-factory/data-flow-external-call">外部呼び出しの公式ドキュメント</a> も併せてご確認ください。<br>この記事では、一枚目にあるデータの各行のデータをbody として、外部のAPI にPOST します。最後に、その他の例についても簡単にはなりますが、記載いたします。</p><p>POST する前のデータ<br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-about-1.png">    </p><p>POST した後のデータ<br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-about-2.png"></p><p>一行目の id=7065 の行をbody としてPOST した結果<br><code>&#123;&#39;id&#39;: 7065, &#39;title&#39;: &#39;Birth of a Nation, The&#39;, &#39;year&#39;: 1915, &#39;Rating&#39;: 6&#125;</code><br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-about-3.png"></p><h1 id="検証環境"><a href="#検証環境" class="headerlink" title="検証環境"></a>検証環境</h1><ul><li>Azure Data Factory V2 Data Flow</li><li>Azure Functions (REST API用)</li></ul><h1 id="手順"><a href="#手順" class="headerlink" title="手順"></a>手順</h1><h2 id="REST-API-の準備"><a href="#REST-API-の準備" class="headerlink" title="REST API の準備"></a>REST API の準備</h2><p>Data Flow から外部呼び出しを行うAPI の準備をします。<br>Azure Functions を用いて、Data Flow から外部呼び出しどのように行われているか確認するため、受け取ったリクエストをログに吐き出すだけのAPI を作成します。  </p><p>ここでは、下記のようなpython での関数で検証を行います。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import logging</span><br><span class="line"></span><br><span class="line">import azure.functions as func</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main(req: func.HttpRequest) -&gt; func.HttpResponse:</span><br><span class="line">    logging.info(&#x27;Python HTTP trigger function processed a request.&#x27;)</span><br><span class="line">    logging.info(req)</span><br><span class="line">    logging.info(req.get_json())  # bodyの内容をログに吐き出す</span><br><span class="line">    logging.info(req.params)</span><br><span class="line">    </span><br><span class="line">    req_body = req.get_json()</span><br><span class="line">    movie_id = req_body.get(&#x27;id&#x27;)</span><br><span class="line">    logging.info(f&quot;movie&#x27;s id is &#123;movie_id&#125;&quot;)</span><br><span class="line">    return func.HttpResponse(</span><br><span class="line">            &quot;This HTTP triggered function executed successfully. &quot;,</span><br><span class="line">            status_code=200)</span><br></pre></td></tr></table></figure><p>保存を行い、関数URL の取得を行います。<br><img src="/blog/DataFactory/how-to-data-flow-external-call/azurefunctions-1.png">  </p><h2 id="Data-Flow-の準備"><a href="#Data-Flow-の準備" class="headerlink" title="Data Flow の準備"></a>Data Flow の準備</h2><p>外部呼び出しを含むData Flow を作成しました。<br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-1.png">  </p><p>外部呼び出しは、スキーマ修飾子 の中にあります。<br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-2.png">  </p><h2 id="外部呼び出しの設定"><a href="#外部呼び出しの設定" class="headerlink" title="外部呼び出しの設定"></a>外部呼び出しの設定</h2><h3 id="REST-のリンクサービスの作成"><a href="#REST-のリンクサービスの作成" class="headerlink" title="REST のリンクサービスの作成"></a>REST のリンクサービスの作成</h3><p>ベースURL に、Azure Functions で取得したURLを入れ、接続を行います。<br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-3.png">  </p><h3 id="呼び出し変換の設定"><a href="#呼び出し変換の設定" class="headerlink" title="呼び出し変換の設定"></a>呼び出し変換の設定</h3><p>API をたたく際のリンクサービスやヘッダー、API のカスタマイズ等を行います。<br>本検証では各項目を以下のとおり設定しております。実行する API に応じて適宜設定いただきますようお願い致します。<br>現時点では、REST のみがサポートされています。</p><p>要求メソッド：POST<br>要求書式：JSON<br>要求JSON設定：未設定<br>応答書式：JSON<br>応答JSON設定：単一のドキュメント</p><p><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-4.png">  </p><h3 id="Mapping-の設定"><a href="#Mapping-の設定" class="headerlink" title="Mapping の設定"></a>Mapping の設定</h3><p>ここでは、bodyに関する設定を行います。bodyに含めたい列とkey名を指定します。<br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-5.png">  </p><h3 id="Output-の設定"><a href="#Output-の設定" class="headerlink" title="Output の設定"></a>Output の設定</h3><p>POST したResponse に関して設定を行います。<br>今回は、POST が成功したかどうかの状態のみを設定します。<br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-6.png">  </p><h2 id="外部呼ぶ出しの実行結果の確認"><a href="#外部呼ぶ出しの実行結果の確認" class="headerlink" title="外部呼ぶ出しの実行結果の確認"></a>外部呼ぶ出しの実行結果の確認</h2><p>下記のように、データのプレビューから、最新の情報に更新を行うことで、実際にPOST をして結果を確認できます。status が200番が帰っており、API を正常に叩けていることが確認できました。  </p><p><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-result-1.png"> </p><p>Azure Functions 側のログから、どのようにリクエストが飛んできたか確認できます。<br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-about-3.png"></p><h1 id="ご紹介していない機能について"><a href="#ご紹介していない機能について" class="headerlink" title="ご紹介していない機能について"></a>ご紹介していない機能について</h1><p>上記のサンプルでは、使用していない項目についてご紹介します。<br>英語にはなりますが、詳細は、<a href="https://learn.microsoft.com/ja-jp/azure/data-factory/data-flow-external-call">外部呼び出しの公式ドキュメント</a> にございます動画をご覧ください。</p><h2 id="行によって適用するAPI-を変えたいとき"><a href="#行によって適用するAPI-を変えたいとき" class="headerlink" title="行によって適用するAPI を変えたいとき"></a>行によって適用するAPI を変えたいとき</h2><p>公式ドキュメントの動画内にあるとおり、呼び出し変換の設定 -&gt; 行の相対URL に対象の列を指定することで解決できます。<br>動画では、派生列変換を用いて、リンクサービスで指定したベースURL に続く相対URL のための列(ziplookup)を生成しております。<br>その後、外部呼び出し変換の行の相対URL にて列をしてしております。</p><p><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-tips-1.png"><br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-tips-2.png"> </p><h2 id="Response-をデータに加えたいとき"><a href="#Response-をデータに加えたいとき" class="headerlink" title="Response をデータに加えたいとき"></a>Response をデータに加えたいとき</h2><p>API のResponse をデータフローのデータの中に含めたい場合は、上述のOutPut の設定を行います。本文にチェックボックスを加えて、Response のkey名と型についての定義が必要です。</p><p><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-tips-3.png"><br><img src="/blog/DataFactory/how-to-data-flow-external-call/dataflow-tips-4.png"> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#%E7%9B%AE%E6%AC%A1&quot;&gt;目次&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E6%A6%82%E8%A6%81&quot;&gt;概要&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E6%A4%9C%E8%A8%BC%E7%92%B0%E</summary>
      
    
    
    
    
    <category term="Azure" scheme="https://jpaz-bigdata.github.io/blog/tags/Azure/"/>
    
    <category term="Data Factory" scheme="https://jpaz-bigdata.github.io/blog/tags/Data-Factory/"/>
    
    <category term="data flow" scheme="https://jpaz-bigdata.github.io/blog/tags/data-flow/"/>
    
    <category term="外部呼び出し" scheme="https://jpaz-bigdata.github.io/blog/tags/%E5%A4%96%E9%83%A8%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%97/"/>
    
    <category term="external-call" scheme="https://jpaz-bigdata.github.io/blog/tags/external-call/"/>
    
  </entry>
  
  <entry>
    <title>Azure Data Factory のサポートファイルの取得方法</title>
    <link href="https://jpaz-bigdata.github.io/blog/DataFactory/how-to-get-adf-support-file/"/>
    <id>https://jpaz-bigdata.github.io/blog/DataFactory/how-to-get-adf-support-file/</id>
    <published>2023-05-23T00:00:00.000Z</published>
    <updated>2024-01-23T09:20:19.861Z</updated>
    
    <content type="html"><![CDATA[<p>課題解決に向けて、弊社の担当からサポートファイルのご提供をお願いすることがあります。<br>サポートファイルを取得するためには、Azure Data Factory Studio のパイプライン編集画面から取得できます。</p><p><img src="/blog/DataFactory/how-to-get-adf-support-file/how-to-get-adf-support-file-1.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;課題解決に向けて、弊社の担当からサポートファイルのご提供をお願いすることがあります。&lt;br&gt;サポートファイルを取得するためには、Azure Data Factory Studio のパイプライン編集画面から取得できます。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/Dat</summary>
      
    
    
    
    
    <category term="Azure" scheme="https://jpaz-bigdata.github.io/blog/tags/Azure/"/>
    
    <category term="Data Factory" scheme="https://jpaz-bigdata.github.io/blog/tags/Data-Factory/"/>
    
    <category term="サポートファイル" scheme="https://jpaz-bigdata.github.io/blog/tags/%E3%82%B5%E3%83%9D%E3%83%BC%E3%83%88%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB/"/>
    
  </entry>
  
</feed>
